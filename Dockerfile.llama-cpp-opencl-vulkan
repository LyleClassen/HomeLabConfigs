FROM debian:bookworm-slim

ENV DEBIAN_FRONTEND=noninteractive

# Basic build tools + Vulkan GPU stack + shader compiler
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
      git build-essential cmake ca-certificates pkg-config \
      libvulkan-dev mesa-vulkan-drivers vulkan-tools libgomp1 \
      glslang-tools \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Clone llama.cpp and build with Vulkan enabled
RUN git clone https://github.com/ggerganov/llama.cpp.git . && \
    cmake -B build -DGGML_VULKAN=ON && \
    cmake --build build -j $(nproc)

# Default config (can be overridden by env in compose)
ENV LLAMA_MODEL=/models/model.gguf \
    LLAMA_PORT=8080 \
    LLAMA_THREADS=8 \
    LLAMA_N_GPU_LAYERS=35

EXPOSE 8080

# Start llama-server with OpenAI-compatible API
CMD ["bash", "-lc", "./build/bin/llama-server -m ${LLAMA_MODEL} --host 0.0.0.0 --port ${LLAMA_PORT} --n-gpu-layers ${LLAMA_N_GPU_LAYERS} --threads ${LLAMA_THREADS} --api-key dummy"]